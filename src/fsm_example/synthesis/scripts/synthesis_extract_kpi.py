# Prompt: Paul Capgras
# LLM : ChatGPT
# Date : Oct 2025

# The prompt:
'''
Write me a python script with the following functions:

read_log function:
- open the log file named: `results/logs/genus.log`
- Read all the content of the file and count the number of "Fatal", "Error", "Warning", "Info".
- If 'Info', 'Warn', 'Fatal', 'Error' are all present in the same line, ignore the line (meaning do not count these values)
- It should return fatal_nb, error_nb, warning_nb, info_nb variables.

read_area function:
- open the file `results/reports/final_area.rpt`
The file should like this:
```final_area.rpt
============================================================
  Generated by:           Genus(TM) Synthesis Solution 20.10-p001_1
  Generated on:           Oct 24 2025  04:47:19 pm
  Module:                 nssa_top_level
  Operating conditions:   PVT_1P8V_25C 
  Interconnect mode:      global
  Area mode:              timing library
============================================================

 Instance  Module  Cell Count  Cell Area  Net Area   Total Area  Wireload  
---------------------------------------------------------------------------
comparator                 12    228.301     0.000      228.301 Small (D)  
  (D) = wireload is default in technology library
  (T) = wireload mode is 'top'
```
Here you are supposed to read the value 228.301

An other example:
```final_area.rpt
============================================================
  Generated by:           Genus(TM) Synthesis Solution 20.10-p001_1
  Generated on:           Oct 24 2025  03:35:53 pm
  Module:                 comparator
  Operating conditions:   PVT_1P8V_25C 
  Interconnect mode:      global
  Area mode:              timing library
============================================================

 Instance  Module  Cell Count  Cell Area  Net Area   Total Area  Wireload
-------------------------------------------------------------------------
comparator                 18    354.040   169.602      523.642 Small (D)

```
In this one you are supposed to read 523.642
- A good approach could be to detect the line with a couple of "---------------"
- then read the next line: `comparator                 18    354.040   169.602      523.642 Small (D)` split it according to spaces : ' '. And then pick the last value not nul. then stop reading the file.
- the function should return the variable 'area' which is the value read (228.301 in the first example and 523.642 in the second).


read_slack function:
- open the file `results/reports/final_time.rpt`
- Read it line per line starting from the beginning because it is huge file.
- Once you reach a line that looks like the following example, you should save the value associated:
`             Slack:=    7805`
Here you should read "7805"

In this other example:
`             Slack:=       0                  `
You should read "0"

In this other example:
`             Slack:=    -1482                  `
You should read "-1482"

If you don't find this line you should read "unconstrained".
You can stop reading the file after you have read one value.
This value read should be stored in a variable called "slack" and be returned by the function.


read_power function:
- open the file `results/reports/<can_be_anything>_power.rpt`
- It should look like this:
```
Instance: /comparator
Power Unit: W
PDB Frames: /stim#0/frame#0
  -------------------------------------------------------------------------
    Category         Leakage     Internal    Switching        Total    Row%
  -------------------------------------------------------------------------
      memory     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
    register     4.18001e-10  5.28539e-06  5.69938e-07  5.85574e-06  30.14%
       latch     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
       logic     5.36887e-10  2.53679e-06  7.73347e-06  1.02708e-05  52.86%
        bbox     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
       clock     0.00000e+00  0.00000e+00  3.30480e-06  3.30480e-06  17.01%
         pad     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
          pm     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
  -------------------------------------------------------------------------
    Subtotal     9.54888e-10  7.82217e-06  1.16082e-05  1.94313e-05 100.01%
  Percentage           0.00%       40.26%       59.74%      100.00% 100.00%
  -------------------------------------------------------------------------
  ```
And you should read "1.94313e-05"

In this second example:
```
Instance: /nssa_top_level
Power Unit: W
PDB Frames: /stim#0/frame#0
  -------------------------------------------------------------------------
    Category         Leakage     Internal    Switching        Total    Row%
  -------------------------------------------------------------------------
      memory     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
    register     3.66097e-08  4.05398e-04  4.98040e-05  4.55239e-04  64.09%
       latch     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
       logic     1.12083e-08  5.21510e-05  7.50975e-05  1.27260e-04  17.92%
        bbox     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
       clock     0.00000e+00  0.00000e+00  1.27786e-04  1.27786e-04  17.99%
         pad     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
          pm     0.00000e+00  0.00000e+00  0.00000e+00  0.00000e+00   0.00%
  -------------------------------------------------------------------------
    Subtotal     4.78179e-08  4.57549e-04  2.52687e-04  7.10284e-04 100.00%
  Percentage           0.01%       64.42%       35.58%      100.00% 100.00%
  -------------------------------------------------------------------------

```
You should read "7.10284e-04".
A good approach could be to read the line with Subtotal, parse it according to spaces ' ' and then pick the 2nd last value that is not null or empty.

The value read should be put in a variable called "power" and be return by the function


save function:
- take the following input fatal_nb, error_nb, warning_nb, info_nb, area, slack, power
- Open a .csv file if it exists, if not it creates with the following column: date,fatal_nb, error_nb, warning_nb, info_nb, area, slack, power
- Then it should append the date and the input values to this csv files as a new line.
- This csv file is called "synthesis_kpi.csv"


main function:
- Finally you should have a main function that run the previous functions and save the result using the save function. The inputs of the save function are of course the returned values from the previous function.


If a function do not find the file, the associated variables should be "not found" and a message should be printed : "[ERROR][Python] File "file_name" not found.
You do not have to convert the value to numbers, you can keep them as a string if it is easier

'''

#!/usr/bin/env python3
import os
import csv
import glob
from datetime import datetime


def read_log(log_path="results/logs/genus.log"):
    """
    Read the log file and count occurrences of Fatal, Error, Warning, Info.
    Ignore lines that contain Info, Warn, Fatal, and Error all together.
    Returns: fatal_nb, error_nb, warning_nb, info_nb (as strings).
    """
    try:
        fatal_count = 0
        error_count = 0
        warning_count = 0
        info_count = 0

        with open(log_path, "r") as f:
            for line in f:
                # Ignore line if it contains all these tags
                if all(tag in line for tag in ("Info", "Warn", "Fatal", "Error")):
                    continue

                fatal_count += line.count("Fatal")
                error_count += line.count("Error")
                warning_count += line.count("Warning")
                info_count += line.count("Info")

        # Return as strings (easier for CSV + "not found" cases)
        return str(fatal_count), str(error_count), str(warning_count), str(info_count)

    except FileNotFoundError:
        print(f'[ERROR][Python] File "{log_path}" not found.')
        return "not found", "not found", "not found", "not found"


def read_area(area_path="results/reports/final_area.rpt"):
    """
    Read the area report and extract the total area value.
    Strategy:
      - Find the line that is a row of dashes (---...).
      - Read the next non-empty line.
      - Split it and take the last numeric token (e.g., 228.301 or 523.642).
    Returns: area (as string) or "not found".
    """
    try:
        with open(area_path, "r") as f:
            read_next_data_line = False

            for line in f:
                stripped = line.strip()

                # Detect the dashed separator line
                if stripped and set(stripped) == {"-"}:
                    read_next_data_line = True
                    continue

                if read_next_data_line:
                    # This should be the data line like:
                    # comparator                 18    354.040   169.602      523.642 Small (D)
                    if not stripped:
                        # Skip empty lines until we find data
                        continue

                    parts = stripped.split()
                    area = "not found"

                    # Walk backwards to find the last numeric-ish token
                    for token in reversed(parts):
                        # Heuristic: token containing any digit is a candidate,
                        # but ignore things like "(D)" or "Small" without digits.
                        if any(ch.isdigit() for ch in token):
                            area = token
                            break

                    return area

        # If we reach here, we didn't find the area line
        return "not found"

    except FileNotFoundError:
        print(f'[ERROR][Python] File "{area_path}" not found.')
        return "not found"


def read_slack(slack_path="results/reports/final_time.rpt"):
    """
    Read the timing report and extract the first Slack value.
    Looks for a line containing: 'Slack:=' and reads the number after it.
    Examples:
        '             Slack:=    7805'
        '             Slack:=       0                  '
        '             Slack:=    -1482                  '
    If no Slack line is found, returns "unconstrained".
    Returns: slack (as string) or "not found".
    """
    try:
        slack = "unconstrained"  # default if not found

        with open(slack_path, "r") as f:
            for line in f:
                if "Slack:=" in line:
                    # Split at 'Slack:=' and take the first token after stripping
                    right = line.split("Slack:=", 1)[1].strip()
                    if right:
                        token = right.split()[0]
                        slack = token
                    break

        return slack

    except FileNotFoundError:
        print(f'[ERROR][Python] File "{slack_path}" not found.')
        return "not found"


def read_power(power_dir="results/reports"):
    """
    Read the power report and extract the Subtotal total power value.
    It looks for a file named *_power.rpt inside power_dir.
    In the report, it finds the line starting with "Subtotal" and then
    parses it like:
        Subtotal     ...  <TotalPower> 100.00%
    and takes the second last token (TotalPower).

    Examples:
      'Subtotal     9.54888e-10  7.82217e-06  1.16082e-05  1.94313e-05 100.01%'
      -> power = "1.94313e-05"

      'Subtotal     4.78179e-08  4.57549e-04  2.52687e-04  7.10284e-04 100.00%'
      -> power = "7.10284e-04"

    Returns: power (as string) or "not found".
    """
    # Find the first *_power.rpt file
    pattern = os.path.join(power_dir, "*_power.rpt")
    power_files = glob.glob(pattern)

    if not power_files:
        # No power report found
        print(f'[ERROR][Python] File "{pattern}" not found.')
        return "not found"

    power_path = sorted(power_files)[0]  # pick the first one deterministically

    try:
        with open(power_path, "r") as f:
            for line in f:
                stripped = line.strip()
                if stripped.startswith("Subtotal"):
                    parts = stripped.split()
                    if len(parts) >= 3:
                        # second last token is the total power
                        power = parts[-2]
                        return power
                    break

        # If we reach here, we didn't find a proper Subtotal line
        return "not found"

    except FileNotFoundError:
        # In case the file disappears between glob and open, just in case
        print(f'[ERROR][Python] File "{power_path}" not found.')
        return "not found"


def save(fatal_nb, error_nb, warning_nb, info_nb, area, slack, power,
         csv_path="synthesis_kpi.csv"):
    """
    Save the KPI values into a CSV file.
    - Creates the file with header if it does not exist.
    - Appends a new row with:
      date, fatal_nb, error_nb, warning_nb, info_nb, area, slack, power
    """
    file_exists = os.path.isfile(csv_path)
    # Use ISO-like date string
    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    with open(csv_path, mode="a", newline="") as csvfile:
        writer = csv.writer(csvfile)
        if not file_exists:
            writer.writerow(
                ["date", "fatal_nb", "error_nb", "warning_nb",
                 "info_nb", "area", "slack", "power"]
            )
        writer.writerow(
            [now_str, fatal_nb, error_nb, warning_nb, info_nb, area, slack, power]
        )


def main():
    fatal_nb, error_nb, warning_nb, info_nb = read_log()
    area = read_area()
    slack = read_slack()
    power = read_power()

    save(fatal_nb, error_nb, warning_nb, info_nb, area, slack, power)


if __name__ == "__main__":
    main()
